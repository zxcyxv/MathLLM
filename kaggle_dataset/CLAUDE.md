# MathLLM Project - CLAUDE.MD

## Project Overview

**ëª©í‘œ**: AIMO3 (AI Mathematical Olympiad Progress Prize 3) Kaggle ëŒ€íšŒ ì°¸ê°€
- ì˜¬ë¦¼í”¼ì•„ë“œ ìˆ˜ì¤€ì˜ ìˆ˜í•™ ë¬¸ì œë¥¼ LaTeX í˜•ì‹ìœ¼ë¡œ í‘¸ëŠ” ì˜¤í”ˆì†ŒìŠ¤ AI ëª¨ë¸ ê°œë°œ
- ìƒê¸ˆ: 1ìœ„ $262,144 / Overall Progress Prize (47/50 ë‹¬ì„± ì‹œ) $1,589,248+

---

## Current Status (2024-12)

### âœ… ì™„ë£Œëœ ì‘ì—…

1. **TRM ì•„í‚¤í…ì²˜ êµ¬í˜„**
   - Qwen-2.5-Math-1.5B + TRM í†µí•© ì™„ë£Œ
   - Same-dimension architecture (3584) ì ìš©
   - 3-level recursion (N_sup=16, T=3, n=6)

2. **í›ˆë ¨ íŒŒì´í”„ë¼ì¸**
   - ChatML í˜•ì‹ ì ìš© (`apply_chat_template()`)
   - GSM8K `#### N` â†’ `\boxed{N}` ë³€í™˜
   - Deep Supervision + EMA êµ¬í˜„
   - Gradient accumulation (Step-wise State Offloading)

3. **ì¶”ë¡  íŒŒì´í”„ë¼ì¸**
   - KV Cache êµ¬í˜„ (ì¶”ë¡  ì†ë„ ê°œì„ )
   - `generate()` í•¨ìˆ˜ êµ¬í˜„
   - EOS í† í° ì²˜ë¦¬ ìˆ˜ì •

4. **ë°ì´í„°ì…‹ ì§€ì›**
   - GSM8K (7.5K samples)
   - NuminaMath-CoT (860K samples) â† **NEW**
   - MATH (7.5K samples)

5. **í‰ê°€ ìŠ¤í¬ë¦½íŠ¸**
   - `eval/trm_eval_simple.py` (train/test split ì§€ì›)
   - ì „ì²´ ì¶œë ¥ í‘œì‹œ ì˜µì…˜

6. **ë¬¸ì„œí™”**
   - `ARCHITECTURE.md` - ìƒì„¸ ì•„í‚¤í…ì²˜ ë¬¸ì„œ
   - `ISSUES.md` - ë°œê²¬ëœ ë²„ê·¸ì™€ í•´ê²° ë°©ë²•

### ğŸ”„ ì§„í–‰ ì¤‘

- NuminaMath-CoT ë°ì´í„°ì…‹ìœ¼ë¡œ ëŒ€ê·œëª¨ í›ˆë ¨ ì¤€ë¹„

### ğŸ“‹ TODO

1. **í›ˆë ¨ ì‹¤í–‰**
   - [ ] NuminaMath-CoTë¡œ ë³¸ê²© í›ˆë ¨
   - [ ] ì ì ˆí•œ epoch/sample ìˆ˜ ê²°ì •
   - [ ] ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ë° í‰ê°€

2. **Kaggle ì œì¶œ ì¤€ë¹„**
   - [ ] `upload_kaggle_dataset.py`ë¡œ ì½”ë“œ ì—…ë¡œë“œ
   - [ ] Kaggle ë…¸íŠ¸ë¶ ì‘ì„±
   - [ ] ì¶”ë¡  ì‹œê°„ ìµœì í™” (5ì‹œê°„ ì œí•œ)

3. **ì„±ëŠ¥ ê°œì„ **
   - [ ] í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
   - [ ] ë” í° ëª¨ë¸ (7B) ì‹¤í—˜
   - [ ] Self-consistency / majority voting

---

## Competition Constraints

| í•­ëª© | ì œí•œ |
|------|------|
| GPU Notebook | â‰¤ 5ì‹œê°„ |
| CPU Notebook | â‰¤ 9ì‹œê°„ |
| ì¸í„°ë„· | ë¹„í™œì„±í™” |
| ì •ë‹µ í˜•ì‹ | 0-99999 ì •ìˆ˜ |
| ë¬¸ì œ ìˆ˜ | Public 50 / Private 50 |
| í‰ê°€ ë°©ì‹ | 2íšŒ ì‹¤í–‰, ë‘˜ ë‹¤ ë§ìœ¼ë©´ 1ì , í•˜ë‚˜ë§Œ 0.5ì  |

---

## Quick Start

### í›ˆë ¨

```bash
# GSM8Kë¡œ í›ˆë ¨ (7.5K, ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©)
python train_trm.py --dataset gsm8k --epochs 3

# NuminaMathë¡œ í›ˆë ¨ (860K, ë³¸ê²© í›ˆë ¨)
python train_trm.py --dataset numina --num_samples 100000 --epochs 1

# MATHë¡œ í›ˆë ¨ (7.5K, ê²½ì‹œëŒ€íšŒ ìˆ˜ì¤€)
python train_trm.py --dataset math --epochs 3

# ì˜µì…˜ë“¤
python train_trm.py \
    --dataset numina \
    --batch_size 4 \
    --gradient_accumulation 4 \
    --lr 1e-4 \
    --max_length 1024 \
    --freeze_lm_head \        # lm_head ê³ ì • (TRMë§Œ í›ˆë ¨)
    --output_dir ./checkpoints/trm_numina
```

### í‰ê°€

```bash
# GSM8K test set í‰ê°€
python eval/trm_eval_simple.py --checkpoint ./checkpoints/trm/checkpoint-XXX

# ìƒì„¸ ì¶œë ¥
python eval/trm_eval_simple.py --checkpoint ./checkpoints/trm/checkpoint-XXX -v

# train setìœ¼ë¡œ ê²€ì¦
python eval/trm_eval_simple.py --checkpoint ./checkpoints/trm/checkpoint-XXX --split train
```

### Kaggle ì—…ë¡œë“œ

```bash
# Kaggle ë°ì´í„°ì…‹ ìƒì„± ë° ì—…ë¡œë“œ
python upload_kaggle_dataset.py --username YOUR_KAGGLE_USERNAME

# ZIPë§Œ ìƒì„± (ìˆ˜ë™ ì—…ë¡œë“œ)
python upload_kaggle_dataset.py --username YOUR_USERNAME --no-upload
```

---

## Training Datasets

| Dataset | Size | Format | íŠ¹ì§• |
|---------|------|--------|------|
| GSM8K | 7,473 | `#### N` â†’ `\boxed{N}` ë³€í™˜ | ì´ˆì¤‘ë“± ìˆ˜ì¤€ |
| **NuminaMath-CoT** | **859,494** | `\boxed{}` (ë³€í™˜ ë¶ˆí•„ìš”) | ë‹¤ì–‘í•œ ì†ŒìŠ¤, ì¶”ì²œ |
| MATH | 7,500 | `\boxed{}` (ë³€í™˜ ë¶ˆí•„ìš”) | ê²½ì‹œëŒ€íšŒ ìˆ˜ì¤€ |

**Column ë§¤í•‘:**
- GSM8K: `question`, `answer`
- NuminaMath/MATH: `problem`, `solution`

---

## Architecture Summary

### Same-Dimension Architecture
```
Qwen [3584] â†’ Identity â†’ TRM [3584] â†’ Qwen lm_head [3584â†’vocab]
```

### 3-Level Recursion

| Level | Parameter | Value | ì—­í•  |
|-------|-----------|-------|------|
| Level 1 | N_supervision | 16 | Deep Supervision steps |
| Level 2 | T_recursion | 3 | Deep Recursion (T-1 no_grad + 1 grad) |
| Level 3 | n_latent | 6 | Latent Recursion (z updates) |

### Effective Depth
```
Depth = 2 Ã— (n + 1) Ã— T Ã— N_sup = 2 Ã— 7 Ã— 3 Ã— 16 = 672 layers
```

### Parameter Count

| Component | Parameters | Trainable |
|-----------|------------|-----------|
| Qwen Backbone | ~1.5B | âŒ Frozen |
| Interface (y_init) | ~3.5K | âœ… |
| TRM Block | ~257M | âœ… |
| TRM Heads (lm_head) | ~545M | âœ… (or frozen) |
| **Total Trainable** | **~802M** (or ~257M with `--freeze_lm_head`) |

---

## File Structure

```
MathLLM/
â”œâ”€â”€ CLAUDE.md                    # í”„ë¡œì íŠ¸ ë¬¸ì„œ (ì´ íŒŒì¼)
â”œâ”€â”€ ARCHITECTURE.md              # ìƒì„¸ ì•„í‚¤í…ì²˜ ë¬¸ì„œ
â”œâ”€â”€ ISSUES.md                    # ë²„ê·¸ ë° í•´ê²° ë°©ë²•
â”œâ”€â”€ train_trm.py                 # TRM í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ upload_kaggle_dataset.py     # Kaggle ì—…ë¡œë“œ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py                # TRMConfig
â”‚   â”œâ”€â”€ interface.py             # TRMInterface
â”‚   â”œâ”€â”€ layers.py                # TRMBlock, TRMAttention, RoPE
â”‚   â”œâ”€â”€ engine.py                # TinyRecursiveTransformer
â”‚   â”œâ”€â”€ model.py                 # QwenTRM
â”‚   â”œâ”€â”€ heads.py                 # TRMHeads
â”‚   â””â”€â”€ train.py                 # Trainer
â”œâ”€â”€ eval/
â”‚   â”œâ”€â”€ trm_eval_simple.py       # TRM í‰ê°€ (ê¶Œì¥)
â”‚   â””â”€â”€ gsm8k_eval.py            # GSM8K í‰ê°€
â””â”€â”€ checkpoints/                 # ëª¨ë¸ ì €ì¥
```

---

## Known Issues & Solutions

ìì„¸í•œ ë‚´ìš©ì€ `ISSUES.md` ì°¸ì¡°. ì£¼ìš” ì´ìŠˆ:

1. **ë°ì´í„° í˜•ì‹ ë¶ˆì¼ì¹˜**: GSM8K `#### N` â†’ `\boxed{N}` ë³€í™˜ í•„ìš”
2. **ChatML í˜•ì‹ ë¯¸ì ìš©**: `apply_chat_template()` ì‚¬ìš© í•„ìˆ˜
3. **EOS í† í° ë¯¸í•™ìŠµ**: labelsì— EOS í¬í•¨ í™•ì¸
4. **attention_mask ë²„ê·¸**: `generate()` ì‹œ mask ì „ë‹¬í•˜ë©´ ë°˜ë³µ ì¶œë ¥
5. **Scheduler N_sup ëˆ„ë½**: total_stepsì— N_supervision ë°˜ì˜ í•„ìˆ˜

---

## Critical Notes

### ChatML í˜•ì‹ í•„ìˆ˜
```python
messages = [
    {"role": "system", "content": "Please reason step by step..."},
    {"role": "user", "content": question},
    {"role": "assistant", "content": answer}  # training only
]
text = tokenizer.apply_chat_template(messages, tokenize=False)
```

### NuminaMathëŠ” ë³€í™˜ ë¶ˆí•„ìš”
```python
# GSM8K: convert_format=True (#### â†’ \boxed)
# NuminaMath/MATH: convert_format=False (ì´ë¯¸ \boxed)
```

### generate() ì‹œ attention_mask ì œê±°
```python
# ì˜ëª»ë¨ - ë°˜ë³µ ì¶œë ¥ ë°œìƒ
model.generate(input_ids, attention_mask=mask, ...)

# ì˜¬ë°”ë¦„
model.generate(input_ids, eos_token_id=tokenizer.eos_token_id, ...)
```

---

## Related Links

- [AIMO3 Competition](https://kaggle.com/competitions/ai-mathematical-olympiad-progress-prize-3)
- [TRM Paper](https://arxiv.org/abs/2510.04871)
- [Qwen-2.5-Math](https://huggingface.co/Qwen/Qwen2.5-Math-1.5B-Instruct)
- [NuminaMath-CoT](https://huggingface.co/datasets/AI-MO/NuminaMath-CoT)
